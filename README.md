# Bishõgrad

A  Bishõ Autograd engine in python along with a lightweight deep neural-network library! (inspired from [mircrograd by Andrej Karpathy](https://github.com/karpathy/micrograd))

## what's Bishõ?
微小 - Bishõ is Japanese word for 'tiny' since my implementation is very tinyyyyy ^_^ compared to PyTorch/Tensorflow

## what's Hako?
箱 - Hako is Japanese word for 'box' , here Hako signify the neurons in our network ;D

## Functionalities to be added : 
- [x] ReLU Activation function
- [ ] Add MLP.training() to automate the whole training code
- [ ] Add Sigmoid, LeakyReLU & other activation functions
- [ ] Add loss functions - categorical loss, mean-square loss etc 
