# Bishõgrad

A lightweight deep neural-network framework (inspired from [mircrograd by Andrej Karpathy](https://github.com/karpathy/micrograd))

## what's Bishõ?
微小 - Bishõ is Japanese word for 'tiny' since my implementation is very tinyyyyy ^^_^^ compared to PyTorch/Tensorflow

## what's Hako?
箱 - Hako is Japanese word for 'box' , here Hako signify the neurons in our network ;D

## Functionalities to be added : 
- [ ] ReLU Activation function
- [ ] Add MLP.training() to automate the whole training code
- [ ] Add Sigmoid, LeakyReLU & other activation functions
- [ ] Add loss functions - categorical loss, mean-square loss etc 